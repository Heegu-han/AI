{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30일차\n",
    "\n",
    "## 신경망\n",
    "\n",
    "### 연습문제\n",
    "- 미니배치는 입력데이터를 여러 조각으로 나누어 각자 훈련시키는 것이다.\n",
    "- 행복데이터에서 배치 크기를 64로 해서 각 배치의 출력값과 오차값을 계산해보자. (배치를 자르기 전에 먼저 데이터를 섞어야 한다.)\n",
    "- 주요 속성 6개를 입력값으로, 행복지수를 출력값으로 하는 회귀 문제이다.\n",
    "- 중간층은 하나이며 256개의 노드를 가진다. 중간층의 활성화 함수는 시그모이드이다.\n",
    "- 가능하면 입력데이터를 정규화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy=pd.read_csv('world_happiness_report_2021.csv')\n",
    "happy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=happy.iloc[:,6:12].values\n",
    "y=happy['Ladder score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 89, 133,  67,  18,  73,  97, 143, 144, 113,  81,  79, 146,   2,\n",
       "        76, 119, 140,  70,  43,  33,  75,  19,  96,  63,  47, 104,  35,\n",
       "       137, 116,  13,  69,  54,  16, 128,  65,  28,  91, 120, 122,  41,\n",
       "         9,  36,  11,  84,  12,  49,  83,  26,  55, 138,  58,  10, 117,\n",
       "        31,   1, 134, 110,  71,  23,  57, 147,  20,  61,  78, 111,  72,\n",
       "       109,  34, 103, 130, 106, 135, 127,  53,  37,  25,   7,  17, 118,\n",
       "       139,  15,  56, 101,  22,  38,  50,  51,  86, 145, 131, 108,  93,\n",
       "        85, 142,   4,  66,  30,  52,  48,  62,  94,  77, 102, 125,  87,\n",
       "       115,  80, 124,  21,  24,  45,  39,  95,  14,   0, 100,  99,  40,\n",
       "         5, 129,  44, 132, 141,   3,  60,  68, 123, 148, 126, 114, 121,\n",
       "        42, 105,  92,  59,   8,  27,  46,   6,  88,  82, 107, 112,  32,\n",
       "        74,  29, 136,  98,  90,  64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=np.random.permutation(range(149))\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=X[idx[:64]]\n",
    "y1=y[idx[:64]]\n",
    "X1=(X1-X1.mean(axis=0))/X1.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=X[idx[64:128]]\n",
    "y2=y[idx[64:128]]\n",
    "X2=(X2-X2.mean(axis=0))/X2.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3=X[idx[128:]]\n",
    "y3=y[idx[128:]]\n",
    "X3=(X3-X3.mean(axis=0))/X3.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=int32, numpy=array([0, 0, 0, 0, 1, 2, 3])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.relu([-3,-2,-1,0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.sin(0.).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 경사하강법 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test)=keras.datasets.mnist.load_data()\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min(),X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '5')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0],cmap='gray_r',vmin=0,vmax=255)\n",
    "plt.title(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X_train.reshape(-1,28*28)/255\n",
    "X_test=X_test.reshape(-1,28*28)/255\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 초기화\n",
    "W=tf.Variable(np.random.normal(0,0.1,size=[784,10]))\n",
    "b=tf.Variable(np.zeros(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float64, numpy=\n",
       "array([[0.06457323, 0.088207  , 0.09379576, ..., 0.03754191, 0.06763539,\n",
       "        0.3292972 ],\n",
       "       [0.04712078, 0.17312135, 0.08276292, ..., 0.01070799, 0.10871429,\n",
       "        0.13007382],\n",
       "       [0.11083919, 0.08990058, 0.05844288, ..., 0.11467887, 0.01792909,\n",
       "        0.40573079],\n",
       "       ...,\n",
       "       [0.13123438, 0.04241704, 0.03760423, ..., 0.04842362, 0.16071272,\n",
       "        0.23585718],\n",
       "       [0.0363834 , 0.17145077, 0.1254504 , ..., 0.04064134, 0.1141165 ,\n",
       "        0.14325198],\n",
       "       [0.15675023, 0.12156284, 0.03439759, ..., 0.020586  , 0.06641229,\n",
       "        0.21616103]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y=tf.nn.softmax(X_train@W+b)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.559592805438929\n",
      "1 2.557433512319234\n",
      "2 2.5552858026979113\n",
      "3 2.553149542409012\n",
      "4 2.551024599343243\n",
      "5 2.548910843409527\n",
      "6 2.5468081464973946\n",
      "7 2.544716382440174\n",
      "8 2.542635426978972\n",
      "9 2.5405651577274257\n",
      "10 2.538505454137199\n",
      "11 2.5364561974642186\n",
      "12 2.534417270735628\n",
      "13 2.532388558717432\n",
      "14 2.5303699478828414\n",
      "15 2.5283613263812783\n",
      "16 2.526362584008028\n",
      "17 2.5243736121745446\n",
      "18 2.522394303879371\n",
      "19 2.5204245536796677\n",
      "20 2.5184642576633443\n",
      "21 2.516513313421767\n",
      "22 2.5145716200230344\n",
      "23 2.5126390779858134\n",
      "24 2.5107155892537167\n",
      "25 2.508801057170209\n",
      "26 2.5068953864540275\n",
      "27 2.5049984831751226\n",
      "28 2.503110254731079\n",
      "29 2.5012306098240265\n",
      "30 2.4993594584380245\n",
      "31 2.4974967118169045\n",
      "32 2.495642282442571\n",
      "33 2.493796084013734\n",
      "34 2.4919580314250798\n",
      "35 2.4901280407468604\n",
      "36 2.4883060292048937\n",
      "37 2.4864919151609692\n",
      "38 2.4846856180936436\n",
      "39 2.4828870585794243\n",
      "40 2.481096158274323\n",
      "41 2.479312839895785\n",
      "42 2.47753702720497\n",
      "43 2.4757686449893876\n",
      "44 2.4740076190458766\n",
      "45 2.4722538761639146\n",
      "46 2.470507344109265\n",
      "47 2.468767951607934\n",
      "48 2.4670356283304486\n",
      "49 2.4653103048764393\n",
      "50 2.46359191275952\n",
      "51 2.4618803843924644\n",
      "52 2.4601756530726693\n",
      "53 2.4584776529678924\n",
      "54 2.4567863191022727\n",
      "55 2.455101587342613\n",
      "56 2.4534233943849264\n",
      "57 2.45175167774124\n",
      "58 2.4500863757266487\n",
      "59 2.4484274274466147\n",
      "60 2.446774772784508\n",
      "61 2.445128352389379\n",
      "62 2.443488107663964\n",
      "63 2.441853980752915\n",
      "64 2.4402259145312475\n",
      "65 2.438603852593007\n",
      "66 2.4369877392401396\n",
      "67 2.4353775194715808\n",
      "68 2.433773138972528\n",
      "69 2.4321745441039324\n",
      "70 2.4305816818921637\n",
      "71 2.4289945000188764\n",
      "72 2.427412946811057\n",
      "73 2.4258369712312535\n",
      "74 2.4242665228679816\n",
      "75 2.4227015519263024\n",
      "76 2.4211420092185776\n",
      "77 2.4195878461553804\n",
      "78 2.418039014736578\n",
      "79 2.4164954675425716\n",
      "80 2.414957157725688\n",
      "81 2.4134240390017316\n",
      "82 2.4118960656416797\n",
      "83 2.4103731924635308\n",
      "84 2.4088553748242907\n",
      "85 2.407342568612103\n",
      "86 2.4058347302385164\n",
      "87 2.4043318166308874\n",
      "88 2.4028337852249155\n",
      "89 2.401340593957308\n",
      "90 2.399852201258571\n",
      "91 2.3983685660459266\n",
      "92 2.3968896477163506\n",
      "93 2.39541540613973\n",
      "94 2.393945801652138\n",
      "95 2.3924807950492237\n",
      "96 2.391020347579714\n",
      "97 2.389564420939029\n",
      "98 2.3881129772629954\n",
      "99 2.3866659791216804\n",
      "100 2.385223389513319\n",
      "101 2.383785171858345\n",
      "102 2.3823512899935246\n",
      "103 2.380921708166185\n",
      "104 2.3794963910285425\n",
      "105 2.3780753036321194\n",
      "106 2.376658411422257\n",
      "107 2.375245680232719\n",
      "108 2.3738370762803824\n",
      "109 2.372432566160015\n",
      "110 2.3710321168391415\n",
      "111 2.3696356956529865\n",
      "112 2.368243270299508\n",
      "113 2.3668548088345056\n",
      "114 2.36547027966681\n",
      "115 2.3640896515535497\n",
      "116 2.3627128935954937\n",
      "117 2.3613399752324664\n",
      "118 2.359970866238843\n",
      "119 2.358605536719106\n",
      "120 2.3572439571034836\n",
      "121 2.3558860981436474\n",
      "122 2.354531930908484\n",
      "123 2.3531814267799316\n",
      "124 2.351834557448882\n",
      "125 2.3504912949111487\n",
      "126 2.3491516114634905\n",
      "127 2.3478154796997086\n",
      "128 2.346482872506796\n",
      "129 2.3451537630611488\n",
      "130 2.343828124824836\n",
      "131 2.342505931541928\n",
      "132 2.341187157234881\n",
      "133 2.3398717762009738\n",
      "134 2.3385597630088037\n",
      "135 2.337251092494835\n",
      "136 2.3359457397599965\n",
      "137 2.3346436801663324\n",
      "138 2.3333448893337057\n",
      "139 2.3320493431365508\n",
      "140 2.3307570177006713\n",
      "141 2.3294678894000933\n",
      "142 2.328181934853954\n",
      "143 2.3268991309234512\n",
      "144 2.3256194547088263\n",
      "145 2.3243428835463966\n",
      "146 2.3230693950056343\n",
      "147 2.3217989668862846\n",
      "148 2.320531577215526\n",
      "149 2.3192672042451763\n",
      "150 2.3180058264489363\n",
      "151 2.3167474225196725\n",
      "152 2.3154919713667446\n",
      "153 2.314239452113368\n",
      "154 2.312989844094012\n",
      "155 2.311743126851845\n",
      "156 2.3104992801362045\n",
      "157 2.309258283900113\n",
      "158 2.3080201182978253\n",
      "159 2.30678476368241\n",
      "160 2.3055522006033713\n",
      "161 2.3043224098042945\n",
      "162 2.303095372220538\n",
      "163 2.3018710689769444\n",
      "164 2.300649481385595\n",
      "165 2.2994305909435915\n",
      "166 2.298214379330865\n",
      "167 2.297000828408025\n",
      "168 2.295789920214229\n",
      "169 2.294581636965088\n",
      "170 2.2933759610506006\n",
      "171 2.292172875033111\n",
      "172 2.290972361645302\n",
      "173 2.2897744037882117\n",
      "174 2.288578984529275\n",
      "175 2.287386087100402\n",
      "176 2.286195694896071\n",
      "177 2.2850077914714535\n",
      "178 2.2838223605405665\n",
      "179 2.282639385974446\n",
      "180 2.2814588517993464\n",
      "181 2.2802807421949676\n",
      "182 2.2791050414926994\n",
      "183 2.277931734173895\n",
      "184 2.27676080486817\n",
      "185 2.2755922383517144\n",
      "186 2.2744260195456394\n",
      "187 2.2732621335143337\n",
      "188 2.2721005654638557\n",
      "189 2.2709413007403345\n",
      "190 2.269784324828399\n",
      "191 2.268629623349626\n",
      "192 2.26747718206101\n",
      "193 2.266326986853451\n",
      "194 2.2651790237502616\n",
      "195 2.264033278905701\n",
      "196 2.2628897386035174\n",
      "197 2.261748389255516\n",
      "198 2.260609217400146\n",
      "199 2.259472209701102\n",
      "200 2.2583373529459485\n",
      "201 2.2572046340447574\n",
      "202 2.256074040028765\n",
      "203 2.2549455580490507\n",
      "204 2.2538191753752224\n",
      "205 2.2526948793941304\n",
      "206 2.251572657608589\n",
      "207 2.250452497636118\n",
      "208 2.2493343872077047\n",
      "209 2.2482183141665675\n",
      "210 2.247104266466955\n",
      "211 2.245992232172943\n",
      "212 2.2448821994572565\n",
      "213 2.243774156600102\n",
      "214 2.242668091988018\n",
      "215 2.2415639941127385\n",
      "216 2.240461851570066\n",
      "217 2.239361653058769\n",
      "218 2.238263387379483\n",
      "219 2.2371670434336286\n",
      "220 2.23607261022235\n",
      "221 2.2349800768454515\n",
      "222 2.233889432500364\n",
      "223 2.232800666481111\n",
      "224 2.2317137681772943\n",
      "225 2.230628727073092\n",
      "226 2.229545532746265\n",
      "227 2.2284641748671796\n",
      "228 2.227384643197839\n",
      "229 2.2263069275909277\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-91b496ebcdb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# categorical cross-entropy:-log(p)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my_oneshot\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mW_grads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_grads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1682\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_MatMulGradAgainstFirstOnly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1684\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_MatMulGradAgainstSecondOnly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1685\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[1;31m# No gradient skipping, so do the full gradient computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGradAgainstSecondOnly\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1663\u001b[0m   \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1665\u001b[1;33m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1666\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5524\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5525\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5526\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   5527\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5528\u001b[0m         transpose_b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_oneshot=np.eye(10)[y_train]\n",
    "eps=np.finfo(float).eps\n",
    "lr=0.001\n",
    "losses=[]\n",
    "for epoch in range(1000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_y=tf.nn.softmax(X_train@W+b)\n",
    "        # categorical cross-entropy:-log(p)\n",
    "        loss=tf.reduce_sum(-y_oneshot*tf.math.log(pred_y+eps))/len(y_train)\n",
    "    W_grads,b_grads=tape.gradient(loss,[W,b])\n",
    "    \n",
    "    W.assign_sub(lr*W_grads)\n",
    "    b.assign_sub(lr*b_grads)\n",
    "    losses.append(loss.numpy())\n",
    "    print(epoch,loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19fbf2c5100>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlw0lEQVR4nO3dd3RVZb7/8fc3nRJ6FYIJxZEmoKEmFB0LdpjBGSyoICKICo7OtUzRaXqdnwVBFFEUrCgKoiOgiEgXCQhSAoIYujQRAkj//v7I8ZrLTSRAkn1y8nmtxcrJ3s/Z+e699vqczXOe/Wxzd0REJHJFBV2AiIgULQW9iEiEU9CLiEQ4Bb2ISIRT0IuIRLiYoAvIS7Vq1Tw5OTnoMkRESoyFCxfucPfqea0Ly6BPTk4mIyMj6DJEREoMM1uX3zp13YiIRDgFvYhIhFPQi4hEOAW9iEiEU9CLiEQ4Bb2ISIRT0IuIRLiICXp3Z9i01SzfvDvoUkREwkrEBP0P+w/z5hfruXbk5yxctyvockREwkbEBH3lcnG83b89VcrF0WvUfOau2RF0SSIiYSFigh6gbuWyvH1be+pWLsPNoxcwLXNr0CWJiATuhEFvZklmNt3MMs1suZkNyqNNFzPbbWaLQ//+mmtdlpktDS0v8glsalRI4K1+7Tm7ViK3vbqQD5ZsLuo/KSIS1goyqdkR4B53X2RmicBCM5vq7iuOazfL3a/IZxvnu3ux9aVULhfH633bcsvoDO4a+yU/HjrK71onFdefFxEJKye8onf3Le6+KPQ6G8gE6hR1YacrMSGWMX3akN6wGv/17le8POfboEsSEQnESfXRm1ky0AqYn8fq9ma2xMwmm1nTXMsd+NjMFppZv1/Ydj8zyzCzjO3bt59MWfkqExfNizelcknTmvztgxU88+lq3L1Qti0iUlIUOOjNrDzwLjDY3fcct3oRcKa7twCGAe/lWpfm7ucClwIDzaxTXtt395HunuruqdWr5zl3/imJj4lm+HXn8ptWdXj84695bMoqhb2IlCoFCnoziyUn5F939/HHr3f3Pe6+N/R6EhBrZtVCv28O/dwGTADaFFLtBRYTHcXj17Tg+rb1GDHjG/4ycRlHjynsRaR0OOGXsWZmwCgg092fzKdNLWCru7uZtSHnA2SnmZUDotw9O/T6YuDvhVd+wUVFGf/s1ozyCTE8P2Mtu/Yf5snftSA+JjqIckREik1BRt2kAb2ApWa2OLTsQaAegLuPAHoAA8zsCPAj0DMU+jWBCTmfFcQAb7j7lMLdhYIzMx64tDFVysbx6OSV7N5/mBG9zqN8fFg+UVFEpFBYOPZXp6amelE/M3ZcxgbuH7+UZmdU4KWbW1O1fHyR/j0RkaJkZgvdPTWvdRF1Z+zJuCY1iedvOI+V32VzzfPz2Lhrf9AliYgUiVIb9AAXNqnJa33bsj37ID2em8fXW7ODLklEpNCV6qAHaJ1chbdva89Rd64ZMU8zX4pIxCn1QQ/QuHYFxg/oQOWysdzw4nymr9oWdEkiIoVGQR+SVKUs4/p3oH71ctw6JoP3vtwUdEkiIoVCQZ9L9cR4xvZrR+vkKgx+azEjZ36ju2hFpMRT0B8nMSGWl3u35vJzavPIpJX87YMVuotWREo03SmUh4TYaIb1bMUZFRN4Yda3bNn9I0/3bEVCrO6iFZGSR1f0+YiKMv50eRP+ekUTPl6xletfnM+ufYeCLktE5KQp6E+gT3oKw687l6WbdvPb5+ay4XvdWCUiJYuCvgAua16b1/u2Zee+Q3R/dg5fbfwh6JJERApMQV9ArZOr8O6ADsTHRNNz5OdMX6mx9iJSMijoT0LDGuWZMDBnrH3fVzIY+8X6oEsSETkhBf1JqpGYwNh+7UlrWI37xy/l8Y9WcUzDL0UkjCnoT0H5+BhG3ZRKz9ZJPDN9DXeN/ZIDh48GXZaISJ40jv4UxUZH8ehvmpNcrRz/PXklm3/4kZE3plJN89qLSJjRFf1pMDP6d27Ac9efy/LNe+j+7BzWbNNUxyISXhT0heDS5rV567b2/HjoGN2fncucNTuCLklE5H8o6AtJy6RKvDewA2dULMNNL32hETkiEjYU9IWobuWyjBvQng6hETmPTs7UiBwRCdwJg97MksxsupllmtlyMxuUR5suZrbbzBaH/v0117quZrbKzNaY2f2FvQPhpkJCLC/dlMoN7erx/Iy1DHxjET8e0ogcEQlOQUbdHAHucfdFZpYILDSzqe6+4rh2s9z9itwLzCwaGA5cBGwEFpjZ+3m8N6LEREfxj6ubkVKtPP/8cAWbRs5jZK9UalVMCLo0ESmFTnhF7+5b3H1R6HU2kAnUKeD22wBr3H2tux8CxgJXn2qxJYmZcUt6Ci/0SuWbbXu56pnZLN7wQ9BliUgpdFJ99GaWDLQC5uexur2ZLTGzyWbWNLSsDrAhV5uNFPxDIiJc2KQm797egbiYKH73/DwmLtYjCkWkeBU46M2sPPAuMNjd9xy3ehFwpru3AIYB7/30tjw2lee3k2bWz8wyzCxj+/btBS2rRDi7VgUmDkyjZVIlBo1dzL+nrNSXtCJSbAoU9GYWS07Iv+7u449f7+573H1v6PUkINbMqpFzBZ+Uq2ldYHNef8PdR7p7qrunVq9e/SR3I/xVLR/Pa7e05do2STz72Tfc9tpC9h48EnRZIlIKFGTUjQGjgEx3fzKfNrVC7TCzNqHt7gQWAI3MLMXM4oCewPuFVXxJExcTxSPdm/PwlU34dOU2fvusHmQiIkWvIFf0aUAv4IJcwycvM7P+ZtY/1KYHsMzMlgBDgZ6e4whwB/AROV/ivu3uy4tgP0oMM+PmtBRG927Nlt0/cvXwOcxfuzPoskQkgpl7+PUVp6amekZGRtBlFLm12/fS95UM1u/czz+6NePaNvWCLklESigzW+juqXmt052xAapfvTwTbk+jQ8NqPDB+KQ+/v5wjR48FXZaIRBgFfcAqlsm5k/aW9BRGz83ixpe+4Pt9h4IuS0QiiII+DMRER/GXK5rw+DUtyFi3iyuHzWbZpt1BlyUiEUJBH0Z6nFeXd/q3x9357XNzmfDlxqBLEpEIoKAPM+fUrcT7d6bTMqkSd7+1hL9/sILD6rcXkdOgoA9D1crH81rftvRJS+GlOd/Sa9R8duw9GHRZIlJCKejDVGx0FH+9sglP/b4FX67/gauGzearjT8EXZaIlEAK+jDXvVVd3h3QATOjx4h5jMvYcOI3iYjkoqAvAZrVqcgHd6aTemZl/vjOVzw0cZn67UWkwBT0JUSVcnG80qcNt3ZMYcy8dVz3wuds23Mg6LJEpARQ0JcgMdFR/OnyJjzdsyXLNu3hsqGz+Vzz5IjICSjoS6CrW9bhvYFpVEiI4foX5/P8jG8IxzmLRCQ8KOhLqF/VSmTiHWlc0rQmj05eSf/XFrLnwOGgyxKRMKSgL8ESE2IZft25/OWKJkzL3MZVw2aTueX4h3+JSGmnoC/hfnoI+Zv92rH/0FG6PzuHdxZq6gQR+ZmCPkK0Tq7Ch3d1pFVSZe4dt4QHxi/lwOGjQZclImFAQR9BqifG8+otbRjQpQFvfrGeHiP0qEIRUdBHnJjoKO7rejYv3JjKup37uWLYbD5duTXoskQkQAr6CHVRk5r858506lQqQ5/RGTwyKVN304qUUgr6CHZm1XKMv70DN7Srx8iZa/nd8/PYuEtdOSKljYI+wiXERvPPbs155rpWrN66l8uHzubj5d8FXZaIFKMTBr2ZJZnZdDPLNLPlZjboF9q2NrOjZtYj17IsM1tqZovNLKOwCpeTc8U5Z/DhXekkVSlDv1cX8vcPVnDoiLpyREqDglzRHwHucffGQDtgoJk1Ob6RmUUDjwEf5bGN8929pbunnla1clrOrFqOdwd04OYOybw051uu0agckVLhhEHv7lvcfVHodTaQCdTJo+mdwLvAtkKtUApVfEw0D1/VlBE3nMvaHfu4bOgspizbEnRZIlKETqqP3sySgVbA/OOW1wG6AyPyeJsDH5vZQjPr9wvb7mdmGWaWsX379pMpS05B12a1mXRXR+pXK0f/1xbx0MRlHDyiG6xEIlGBg97MypNzxT7Y3Y+fUGUIcJ+755UUae5+LnApOd0+nfLavruPdPdUd0+tXr16QcuS05BUpSzj+negT1rOHPe/fW4uWTv2BV2WiBSyAgW9mcWSE/Kvu/v4PJqkAmPNLAvoATxrZt0A3H1z6Oc2YALQ5vTLlsISF5PzbNqRvc5jfegGqw+WbA66LBEpRAUZdWPAKCDT3Z/Mq427p7h7srsnA+8At7v7e2ZWzswSQ9spB1wMLCu06qXQXNy0FpMGdeSsmuW5880v+eO4Jew7eCToskSkEMQUoE0a0AtYamaLQ8seBOoBuHte/fI/qQlMyPmsIAZ4w92nnHK1UqTqVi7LW7e15+lPVjP8szVkrNvF0J6taF63YtClichpsHB8MlFqaqpnZGjIfZA+X7uTu99azI69B/njJb+ib3p9oqIs6LJEJB9mtjC/Iey6M1by1K5+VSYP6sgFZ9fgkUkruenlL/QwcpESSkEv+apUNo4RN5zHI92bsyDre7o+PUszYYqUQAp6+UVmxnVt6/HBHenUSIynz+gMHn5/uR5qIlKCKOilQBrVTOS9gWn0Tktm9Nwsug2fw+qt2UGXJSIFoKCXAkuIjeahK5vy8s2t2Z59kCuGzea1z9cRjl/oi8jPFPRy0s4/uwaTB3ekTUoV/vzeMm59ZSE79h4MuiwRyYeCXk5JjcQExvRuw58vb8zMr7fTdchMfVErEqYU9HLKoqKMvh3r8/6daVQrn/NF7YMTlrL/kO6oFQknCno5bWfXqsDEO9Lo16k+b36xnsuensWX63cFXZaIhCjopVDEx0Tz4GWNeaNvOw4dOUaPEfN4aurXeiC5SBhQ0Euhat+gKpMHd+KqFmfw9LTV9Bgxj7Xb9wZdlkippqCXQlexTCxP/b4lz1zXiqwd+7h8qIZhigRJQS9F5opzzuCjwZ0478zK/Pm9ZdwyJoNt2ZovR6S4KeilSNWqmMArfdrw0JVNmL1mB12HzGLKsu+CLkukVFHQS5GLijJ6p6Xw4Z3p1K6YQP/XFnL3W4vZvf9w0KWJlAoKeik2P82XM+jXjXh/yWYuHjKD6au2BV2WSMRT0Euxio2O4u6LzuK929OoWCaW3i8v4P53vyL7gK7uRYqKgl4C0bxuRd6/I53bOtfn7YwNdB0yi7lrdgRdlkhEUtBLYBJio3ng0saM69+BuJgorntxPg+/v1xTKIgUMgW9BO68Mysz6a6O3NwhZ677y56excJ13wddlkjEUNBLWCgTF83DVzXlzVvbceSY02PEPB6dlKknWYkUghMGvZklmdl0M8s0s+VmNugX2rY2s6Nm1iPXsq5mtsrM1pjZ/YVVuESm9g2qMmVwJ3q2rsfzM9dy5bDZLNnwQ9BliZRoBbmiPwLc4+6NgXbAQDNrcnwjM4sGHgM+Om7ZcOBSoAlwbV7vFcmtfHwMj/6mOWP6tCH7wBG6PzuHRyfr6l7kVJ0w6N19i7svCr3OBjKBOnk0vRN4F8g9MLoNsMbd17r7IWAscPVpVy2lQuezqvPxHzrx+9ZJPD9jLZcNnUVGlvruRU7WSfXRm1ky0AqYf9zyOkB3YMRxb6kDbMj1+0by/pDAzPqZWYaZZWzfvv1kypIIViEhlkd/cw6v3dKWg4ePcc3z8/jbBxqZI3IyChz0ZlaenCv2we6+57jVQ4D73P34/1tbHpvKcwpDdx/p7qnunlq9evWCliWlRHqjanx8dydubHcmL8/J4pIhM5n7jcbdixREgYLezGLJCfnX3X18Hk1SgbFmlgX0AJ41s27kXMEn5WpXF9h8OgVL6VUuPoa/Xd2Mt/q1I9qM616Yz58mLNVdtSInUJBRNwaMAjLd/cm82rh7irsnu3sy8A5wu7u/BywAGplZipnFAT2B9wureCmd2tavyuRBnbi1YwpvfrGeS56ayWeaM0ckXwW5ok8DegEXmNni0L/LzKy/mfX/pTe6+xHgDnJG4mQCb7v78tOuWkq9MnHR/OnyJrwzoANl42O4+eUF3DtuiWbEFMmDheNTf1JTUz0jIyPoMqSEOHjkKMOmreG5Gd9QpVwc/+rWjIub1gq6LJFiZWYL3T01r3W6M1ZKvPiYaO695FdMHJhGtfLx9Ht1IXe8sYjt2QeDLk0kLCjoJWI0q1ORiQPT+MNFZ/Hx8q1c+OQM3s7YoGfVSqmnoJeIEhcTxV2/bsSkQemcVbM8//XOV9wwaj5ZO/YFXZpIYBT0EpEa1kjkrX7t+Vf3Zny1YTeXDJnJc599w+Gjx4IuTaTYKeglYkVFGde3PZNP7unM+b+qwWNTVnLVM3P4auMPQZcmUqwU9BLxalZIYESv83i+13l8v+8g3YbP4R//WcG+g5pGQUoHBb2UGpc0rcXUP3Tmurb1GDX7Wy7WjVZSSijopVSpkBDLP7s1Z1z/9iTERnHzywsYNPZLduzVUEyJXAp6KZVaJ1dh0qCODPp1IyYt3cKFT87gnYUbNRRTIpKCXkqt+Jho7r7oLCbd1ZEG1ctz77glXPvC56zZtjfo0kQKlYJeSr1GNRMZd1t7HunenBWb93Dp0zN54uNVeqKVRAwFvQg5QzGva1uPT+/twpXnnMGwT9dw8VMzmfG1HoIjJZ+CXiSXauXjefL3LXmjb1tiooybXvqCO95YxNY9B4IuTeSUKehF8tChYTUmD+6YM2/Oiq1c+MQMxszN4ugxfVkrJY+CXiQf8THR3PXrRnw8uBMt61XiofeX0234HJZu3B10aSInRUEvcgLJ1crxSp82DLu2Fd/tOcDVw2fz8PvL2aNHGEoJoaAXKQAz48oWZ/DJHzpzQ7szGTMviwufmMGHX23R2HsJewp6kZNQsUwsf7+6Ge/dnkb1xHgGvrGIm19ewLqdmgZZwpeCXuQUtEiqxMSBaTx0ZRMWrtvFRU/N5KmpX2vsvYQlBb3IKYqJjqJ3WgrT7ulM16a1eHraai56agafrNgadGki/8sJg97MksxsupllmtlyMxuUR5urzewrM1tsZhlmlp5rXZaZLf1pXWHvgEjQalZIYOi1rXjj1rYkxETT95UM+oxWd46EDzvRF0lmVhuo7e6LzCwRWAh0c/cVudqUB/a5u5vZOcDb7n52aF0WkOruOwpaVGpqqmdk6DNBSp7DR48xek4WQz75msPHnP6dG3B7lwYkxEYHXZpEODNb6O6pea074RW9u29x90Wh19lAJlDnuDZ7/edPjHKAhiFIqRQbHcWtnerz6b1d6Nq0FkOnrebCJ9WdI8E6qT56M0sGWgHz81jX3cxWAh8CfXKtcuBjM1toZv1Oo1aREuOn7pw3b21HmVh150iwTth18z8Nc7pnZgD/cvfxv9CuE/BXd78w9PsZ7r7ZzGoAU4E73X1mHu/rB/QDqFev3nnr1q076Z0RCUeHjx5jzNwsnpqq7hwpOr/UdVOgoDezWOA/wEfu/mQB2n8LtD6+X97MHgb2uvvjv/R+9dFLJNq65wCPTMpk4uLN1K1choeubMqFjWtgZkGXJhHgtProLecsHAVk5hfyZtYw1A4zOxeIA3aaWbnQF7iYWTngYmDZqe2GSMlWs0ICT/fM6c4pGxfNraHunKwd6s6RolWQUTfpwCxgKXAstPhBoB6Au48ws/uAG4HDwI/AH919tpnVByaE3hMDvOHu/zpRUbqil0j3U3fOkE9Wc/DIUfqkp3DnBY0oHx8TdGlSQp12101xU9BLabEt+wD/nrKKdxZupHpiPPd3PZvureoQFaXuHDk5p9V1IyJFp0ZiAo9f04L3BqZRp1IZ7hm3hN88N5fFG34IujSJIAp6kTDQMqkS4wd04IlrWrDphx/pNnwO945bwrZsPdlKTp+CXiRMREUZvz2vLtPv7cJtneszcfEmLnh8Bs/P+IZDR46deAMi+VDQi4SZ8vExPHBpYz6+uzNtU6rw6OSVXDJkJtNXbgu6NCmhFPQiYSqlWjlG3dya0b1bYwa9Ry+g98tfsHb73qBLkxJGQS8S5rr8qgZTBnXiz5c3JiNrF5cMmckjkzLJ1qMMpYAU9CIlQFxMFH075kyW1r1VHV6YtZbzH/+MN79Yz9Fj4TdEWsKLgl6kBKmeGM+/e7Rg4sA0kquW44HxS7l86CzmrCnwLOBSCinoRUqgc+pWYlz/9gy/7lz2HjzC9S/Op++YBeq/lzwp6EVKKDPj8nNq88kfOnNf17P5fO33XPzUTP72wXJ+2H8o6PIkjCjoRUq4hNhoBnRpwPR7u3BNahJj5mbR+f99xstzvuXwUY2/FwW9SMSonhjPo79pzqRBHWlepyJ/+2AFlwyZybTMrYTjnFZSfBT0IhHm7FoVePWWNoy6KWd+q1vGZNBr1Bes/G5PwJVJUBT0IhHIzPh145p8NLgTD13ZhKWbdnPZ07N4YPxStmcfDLo8KWYKepEIFhsdRe+0FGb8sQs3dUhmXMYGzn/8M5777BsOHD4adHlSTBT0IqVApbJxPHRlUz66uxPt6lflsSkrufDJGUxcvIljuuEq4inoRUqRBtXL8+JNqbzety0VEmIZNHYx3Z6dw7xvdgZdmhQhBb1IKZTWsBr/uTOdJ65pwY7sg1z7wufcMnoBa7ZlB12aFAE9SlCklDtw+Cgvz8ni2elr2H/4KL9vncTgCxtRIzEh6NLkJOiZsSJyQt/vO8TQaat57fN1xMVEcVunBtzaKYWycXpgeUmgoBeRAvt2xz7+PWUlk5d9R/XEeP5w0Vlcc15dYqLV0xvOTuvh4GaWZGbTzSzTzJab2aA82lxtZl+Z2WIzyzCz9FzruprZKjNbY2b3n96uiEhRS6lWjuduOI93B7QnqXIZHhi/lMuGzuLTlbrDtqQ64RW9mdUGarv7IjNLBBYC3dx9Ra425YF97u5mdg7wtrufbWbRwNfARcBGYAFwbe735kVX9CLhwd2Zsuw7Hpuykqyd+2lfvyp/urwxzepUDLo0Oc5pXdG7+xZ3XxR6nQ1kAnWOa7PXf/7EKAf89LoNsMbd17r7IWAscPWp7YaIFDcz49Lmtfn47s48fGUTVn63hyuGzWbw2C/ZuGt/0OVJAZ1Up5uZJQOtgPl5rOtuZiuBD4E+ocV1gA25mm3kuA+JXO/vF+r2ydi+ffvJlCUiRSwuJoqb01KY8V/nM6BLAyYv+44LHp/BP/6zgu/3aUrkcFfgoA91z7wLDHb3/zM7krtPcPezgW7AP356Wx6byrOvyN1Hunuqu6dWr169oGWJSDGqkBDLfV3PZvq9XejW6gxenvMtnf89nWHTVrP/0JGgy5N8FCjozSyWnJB/3d3H/1Jbd58JNDCzauRcwSflWl0X2HyKtYpImDijUhn+3aMFUwZ3ol2Dqjwx9Ws6/7/PePXzdZoDPwwVZNSNAaOATHd/Mp82DUPtMLNzgThgJzlfvjYysxQziwN6Au8XVvEiEqyzaibywo2pvDugPSlVy/GX95Zx0ZMz+GDJZs2hE0YKMuomHZgFLAV++qh+EKgH4O4jzOw+4EbgMPAj8Ed3nx16/2XAECAaeMnd/3WiojTqRqTkcXemr9rGY5NXsWprNs3qVOD+ro1Jb1Qt6NJKBd0wJSLF5ugx570vN/Hk1K/Z9MOPpDesxn1dz6Z5XQ3JLEoKehEpdgePHOW1z9fzzKer2bX/MJefU5t7L/4VKdXKBV1aRFLQi0hg9hw4zAsz1/LirJyHlf++dRKDft2IGhU0aVphUtCLSOC2ZR9g2LQ1vPnFemKjo7glPYV+netTISE26NIigoJeRMJG1o59PDH1az5YsplKZWMZ0LkBN7ZPpkxcdNCllWgKehEJO8s27ebfH61i5tfbqZEYz50XNOT3resRF6NZMk+Fgl5Ewtb8tTt5/ONVLMjaRd3KZRh84Vl0b1WH6Ki8bqyX/JzWpGYiIkWpbf2qvH1be0b3bk2lsrHcO24JlwyZyaSlW3TTVSFR0ItI4MyMLr+qwQd3pPPc9ecCcPvri7hq+Gymr9qmefBPk4JeRMLGT9MifzS4E09c04If9h+m98sL+N3z85i/dmfQ5ZVY6qMXkbB16Mgx3srYwLBpq9mWfZBOZ1Xn3ovP4py6lYIuLezoy1gRKdF+PHSUVz/P4rnPvmHX/sN0bVqLP1x8FmfVTAy6tLChoBeRiJB94DAvzc7ihVlr2XfoCN1b1mHwhWdRr2rZoEsLnIJeRCLKrn2HGDHzG8bMzeLIUeea1CTuuKAhdSqVCbq0wCjoRSQibdtzgGemr2HsFxtwnJ6t6zHw/IbUqlj65tFR0ItIRNv0w48Mn76GtxdsICrKuK5NPW7v0qBUTZymoBeRUmHD9/t55tM1vLNoIzFRRq92Z9K/SwOqlY8PurQip6AXkVJl3c59DJ22hglfbiQ+JpobO5zJbZ0aUKVcXNClFRkFvYiUSmu372XotNVMXLKZsrHR3JyWzK0d61OpbOQFvoJeREq11VuzeXraav7z1RYS42PonZ7CLekpVCwTOXPhK+hFRICV3+1hyNTVTFn+HRUSYri1Y31uTksmMQIefqKgFxHJZdmm3Qz5ZDWfZG6lUtlY+nWqz03tkykXHxN0aafstILezJKAV4BawDFgpLs/fVyb64H7Qr/uBQa4+5LQuiwgGzgKHMmvkNwU9CJSHL7a+ANPTf2a6au2U6VcHLd1qk+v9mdSNq7kBf7pBn1toLa7LzKzRGAh0M3dV+Rq0wHIdPddZnYp8LC7tw2tywJS3X1HQQtW0ItIcVq0fhdPTf2aWat3UKVcHLd2rM+N7c8sUVf4p/XgEXff4u6LQq+zgUygznFt5rr7rtCvnwN1T69kEZHic269yrx6S1veHdCeZnUq8tiUlaQ/9inDp68h+8DhoMs7bSfVR29mycBMoJm778mnzb3A2e7eN/T7t8AuwIHn3X1kPu/rB/QDqFev3nnr1q07id0QESk8i9bvYui01Xy2ajsVy8TSNz2Fm9KSqRDGX9oWypexZlYemAH8y93H59PmfOBZIN3dd4aWneHum82sBjAVuNPdZ/7S31LXjYiEgyUbfmDotNVMW7mNCgkx9ElPoXdaeA7LPO2gN7NY4D/AR+7+ZD5tzgEmAJe6+9f5tHkY2Ovuj//S31PQi0g4WbZpN09PW83UFVtJTIihd1oKfdKSw+rGq9PqozczA0aR82VrfiFfDxgP9Mod8mZWLvQFLmZWDrgYWHbyuyAiEpxmdSrywo2pfHhXOh0aVGXotNWkPzadxz9axa59h4Iu74QKMuomHZgFLCVneCXAg0A9AHcfYWYvAr8FfupYP+LuqWZWn5yrfIAY4A13/9eJitIVvYiEs8wtexj26WomLf2OcnHR3NghZ2qFIOfS0Q1TIiJFYNV32Qz7dDUfLt1CmdhoerU/k34d61M1gNkyFfQiIkVo9dZshn26hg++2kxCTDQ3tKtHv04NqJ5YfIGvoBcRKQZrtu1l+PQ1TFy8idjoKK5tU4/bOtendsWif8Shgl5EpBh9u2Mfz05fw4QvN2EGPc5LYkDnBkX6EHMFvYhIADZ8v5/nZ37D2ws2ctSdq1uewe1dGtKwRvlC/1sKehGRAG3dc4CRM9fy+vx1HDxyjMua1+aO8xvSuHaFQvsbCnoRkTCwc+9BRs3+llfmrWPvwSNc2Lgmd17QkBZJlU572wp6EZEwsnv/YUbPzeKlOd+y+8fDdDqrOnde0JDWyVVOeZsKehGRMLT34BFe+3wdL85ay469h2ibUoUxfdqQEBt90tv6paAvOZMti4hEmPLxMfTv3ICb2iczdsF6Vn2XfUohfyIKehGRgJWJi6Z3WkqRbf+Ek5qJiEjJpqAXEYlwCnoRkQinoBcRiXAKehGRCKegFxGJcAp6EZEIp6AXEYlwYTkFgplt5+fnz56sasCOQiynpNJx+JmORQ4dh59F4rE4092r57UiLIP+dJhZRn7zPZQmOg4/07HIoePws9J2LNR1IyIS4RT0IiIRLhKDfmTQBYQJHYef6Vjk0HH4Wak6FhHXRy8iIv9bJF7Ri4hILgp6EZEIFzFBb2ZdzWyVma0xs/uDrqe4mVmWmS01s8VmlhFaVsXMpprZ6tDPykHXWdjM7CUz22Zmy3Ity3e/zeyB0DmyyswuCabqopHPsXjYzDaFzovFZnZZrnUReSzMLMnMpptZppktN7NBoeWl8ryACAl6M4sGhgOXAk2Aa82sSbBVBeJ8d2+Za3zw/cA0d28ETAv9HmlGA12PW5bnfofOiZ5A09B7ng2dO5FiNP/3WAA8FTovWrr7JIj4Y3EEuMfdGwPtgIGh/S2t50VkBD3QBljj7mvd/RAwFrg64JrCwdXAmNDrMUC34EopGu4+E/j+uMX57ffVwFh3P+ju3wJryDl3IkI+xyI/EXss3H2Luy8Kvc4GMoE6lNLzAiIn6OsAG3L9vjG0rDRx4GMzW2hm/ULLarr7Fsg5+YEagVVXvPLb79J6ntxhZl+FunZ+6q4oFcfCzJKBVsB8SvF5ESlBb3ksK23jRtPc/Vxyuq8GmlmnoAsKQ6XxPHkOaAC0BLYAT4SWR/yxMLPywLvAYHff80tN81gWUcciUoJ+I5CU6/e6wOaAagmEu28O/dwGTCDnv55bzaw2QOjntuAqLFb57XepO0/cfau7H3X3Y8AL/NwlEdHHwsxiyQn51919fGhxqT0vIiXoFwCNzCzFzOLI+WLl/YBrKjZmVs7MEn96DVwMLCPnGNwUanYTMDGYCotdfvv9PtDTzOLNLAVoBHwRQH3F5qdgC+lOznkBEXwszMyAUUCmuz+Za1WpPS9igi6gMLj7ETO7A/gIiAZecvflAZdVnGoCE3LOb2KAN9x9ipktAN42s1uA9cA1AdZYJMzsTaALUM3MNgIPAf9NHvvt7svN7G1gBTkjMwa6+9FACi8C+RyLLmbWkpyuiCzgNoj4Y5EG9AKWmtni0LIHKaXnBWgKBBGRiBcpXTciIpIPBb2ISIRT0IuIRDgFvYhIhFPQi4hEOAW9iEiEU9CLiES4/w/MqqFPyVEwdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00431578492132879\n",
      "1 0.004313306867747228\n",
      "2 0.004310836622344495\n",
      "3 0.004308374125845143\n",
      "4 0.004305919319595509\n",
      "5 0.004303472145555462\n",
      "6 0.004301032546290253\n",
      "7 0.004298600464962519\n",
      "8 0.004296175845324401\n",
      "9 0.004293758631709798\n",
      "10 0.004291348769026744\n",
      "11 0.004288946202749896\n",
      "12 0.004286550878913159\n",
      "13 0.004284162744102414\n",
      "14 0.00428178174544837\n",
      "15 0.0042794078306195235\n",
      "16 0.004277040947815234\n",
      "17 0.0042746810457589\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-f536fa41b145>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my_oneshot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mW_grads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_grads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m_SoftmaxGrad\u001b[1;34m(op, grad_softmax)\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[0msoftmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m   \u001b[0msum_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_softmax\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgrad_softmax\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msum_channels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    516\u001b[0m   \"\"\"\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6061\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6062\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6063\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   6064\u001b[0m         _ctx, \"Mul\", name, x, y)\n\u001b[0;32m   6065\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 가중치 초기화\n",
    "W=tf.Variable(np.random.normal(0,0.1,size=[784,10]))\n",
    "b=tf.Variable(np.zeros(10))\n",
    "\n",
    "y_oneshot=np.eye(10)[y_train]\n",
    "eps=np.finfo(float).eps\n",
    "lr=0.001\n",
    "losses=[]\n",
    "\n",
    "for epoch in range(100):\n",
    "    for batch in range(600): #batch_size=100\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_y=tf.nn.softmax(X_train[batch*100:(batch+1)*100]@W+b)\n",
    "            # categorical cross-entropy:-log(p)\n",
    "            \n",
    "            loss=tf.reduce_sum(-y_oneshot[batch*100:(batch+1)*100]*tf.math.log(pred_y+eps))/len(y_train)\n",
    "        W_grads,b_grads=tape.gradient(loss,[W,b])\n",
    "    \n",
    "        W.assign_sub(lr*W_grads)\n",
    "        b.assign_sub(lr*b_grads)\n",
    "    losses.append(loss.numpy())\n",
    "    print(epoch,loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.optimizers.RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(10,input_shape=(784,),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 666us/step - loss: 0.3856\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 667us/step - loss: 0.3762\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 675us/step - loss: 0.3669\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 663us/step - loss: 0.3682\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 658us/step - loss: 0.3659\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 691us/step - loss: 0.3535\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 662us/step - loss: 0.3476\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 668us/step - loss: 0.3432\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 686us/step - loss: 0.3444\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 658us/step - loss: 0.3418\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 668us/step - loss: 0.3352\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 669us/step - loss: 0.3345\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 683us/step - loss: 0.3413\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 671us/step - loss: 0.3283\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 691us/step - loss: 0.3260\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 735us/step - loss: 0.3302\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 713us/step - loss: 0.3241\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 707us/step - loss: 0.3261\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 677us/step - loss: 0.3193\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 668us/step - loss: 0.3217\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 670us/step - loss: 0.3180\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 676us/step - loss: 0.3211\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 704us/step - loss: 0.3127\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 672us/step - loss: 0.3127\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 668us/step - loss: 0.3140\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 684us/step - loss: 0.3093\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 690us/step - loss: 0.3183\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 676us/step - loss: 0.3094\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 667us/step - loss: 0.3118\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 683us/step - loss: 0.3082\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 668us/step - loss: 0.3122\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 672us/step - loss: 0.3086\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 673us/step - loss: 0.3092\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 669us/step - loss: 0.3018\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 673us/step - loss: 0.3069\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 679us/step - loss: 0.3021\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 669us/step - loss: 0.3055\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 673us/step - loss: 0.3084\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 669us/step - loss: 0.3029\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 663us/step - loss: 0.3005\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 664us/step - loss: 0.3035\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 668us/step - loss: 0.2971\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 670us/step - loss: 0.3032\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 677us/step - loss: 0.2972\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 685us/step - loss: 0.2950\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 664us/step - loss: 0.2941\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 678us/step - loss: 0.2947\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 675us/step - loss: 0.2981\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 669us/step - loss: 0.2926\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 679us/step - loss: 0.2907\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 668us/step - loss: 0.2965\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 670us/step - loss: 0.2976\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 677us/step - loss: 0.2916\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 718us/step - loss: 0.2922\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 688us/step - loss: 0.2934\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 722us/step - loss: 0.2910\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 697us/step - loss: 0.2824\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 733us/step - loss: 0.2901\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 706us/step - loss: 0.2928\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 715us/step - loss: 0.2896\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 720us/step - loss: 0.2831\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 722us/step - loss: 0.2955\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 728us/step - loss: 0.2858\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 730us/step - loss: 0.2898\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 743us/step - loss: 0.2881\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 727us/step - loss: 0.2852\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 736us/step - loss: 0.2840\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 735us/step - loss: 0.2895\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 746us/step - loss: 0.2883\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 730us/step - loss: 0.2889\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 737us/step - loss: 0.2912\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 740us/step - loss: 0.2823\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 753us/step - loss: 0.2833\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 755us/step - loss: 0.2832\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 746us/step - loss: 0.2897\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 758us/step - loss: 0.2850\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 751us/step - loss: 0.2785\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 748us/step - loss: 0.2816\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 758us/step - loss: 0.2814\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 752us/step - loss: 0.2833\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 756us/step - loss: 0.2817\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 774us/step - loss: 0.2796\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 770us/step - loss: 0.2822\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 756us/step - loss: 0.2880\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 771us/step - loss: 0.2786\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 773us/step - loss: 0.2858\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 784us/step - loss: 0.2749\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 780us/step - loss: 0.2813\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 781us/step - loss: 0.2801\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 782us/step - loss: 0.2779\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 786us/step - loss: 0.2803\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 775us/step - loss: 0.2783\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 762us/step - loss: 0.2734\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 775us/step - loss: 0.2796\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 779us/step - loss: 0.2808\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 782us/step - loss: 0.2865\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 747us/step - loss: 0.2734\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 751us/step - loss: 0.2815\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 745us/step - loss: 0.2780\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 730us/step - loss: 0.2814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19fbfd7ab80>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='sgd')\n",
    "y_oneshot=np.eye(10)[y_train]\n",
    "model.fit(X_train,y_oneshot,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19fc0088c70>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h=model.history.history\n",
    "plt.plot(h['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
