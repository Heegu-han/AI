{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30일차\n",
    "\n",
    "## 신경망\n",
    "\n",
    "### 연습문제\n",
    "- 미니배치는 입력데이터를 여러 조각으로 나누어 각자 훈련시키는 것이다.\n",
    "- 행복데이터에서 배치 크기를 64로 해서 각 배치의 출력값과 오차값을 계산해보자. (배치를 자르기 전에 먼저 데이터를 섞어야 한다.)\n",
    "- 주요 속성 6개를 입력값으로, 행복지수를 출력값으로 하는 회귀 문제이다.\n",
    "- 중간층은 하나이며 256개의 노드를 가진다. 중간층의 활성화 함수는 시그모이드이다.\n",
    "- 가능하면 입력데이터를 정규화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy=pd.read_csv('world_happiness_report_2021.csv')\n",
    "happy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=happy.iloc[:,6:12].values\n",
    "y=happy['Ladder score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 89, 133,  67,  18,  73,  97, 143, 144, 113,  81,  79, 146,   2,\n",
       "        76, 119, 140,  70,  43,  33,  75,  19,  96,  63,  47, 104,  35,\n",
       "       137, 116,  13,  69,  54,  16, 128,  65,  28,  91, 120, 122,  41,\n",
       "         9,  36,  11,  84,  12,  49,  83,  26,  55, 138,  58,  10, 117,\n",
       "        31,   1, 134, 110,  71,  23,  57, 147,  20,  61,  78, 111,  72,\n",
       "       109,  34, 103, 130, 106, 135, 127,  53,  37,  25,   7,  17, 118,\n",
       "       139,  15,  56, 101,  22,  38,  50,  51,  86, 145, 131, 108,  93,\n",
       "        85, 142,   4,  66,  30,  52,  48,  62,  94,  77, 102, 125,  87,\n",
       "       115,  80, 124,  21,  24,  45,  39,  95,  14,   0, 100,  99,  40,\n",
       "         5, 129,  44, 132, 141,   3,  60,  68, 123, 148, 126, 114, 121,\n",
       "        42, 105,  92,  59,   8,  27,  46,   6,  88,  82, 107, 112,  32,\n",
       "        74,  29, 136,  98,  90,  64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=np.random.permutation(range(149))\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=X[idx[:64]]\n",
    "y1=y[idx[:64]]\n",
    "X1=(X1-X1.mean(axis=0))/X1.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=X[idx[64:128]]\n",
    "y2=y[idx[64:128]]\n",
    "X2=(X2-X2.mean(axis=0))/X2.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3=X[idx[128:]]\n",
    "y3=y[idx[128:]]\n",
    "X3=(X3-X3.mean(axis=0))/X3.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=int32, numpy=array([0, 0, 0, 0, 1, 2, 3])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.relu([-3,-2,-1,0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.sin(0.).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 경사하강법 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test)=keras.datasets.mnist.load_data()\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min(),X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '5')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0],cmap='gray_r',vmin=0,vmax=255)\n",
    "plt.title(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X_train.reshape(-1,28*28)/255\n",
    "X_test=X_test.reshape(-1,28*28)/255\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 초기화\n",
    "W=tf.Variable(np.random.normal(0,0.1,size=[784,10]))\n",
    "b=tf.Variable(np.zeros(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float64, numpy=\n",
       "array([[0.06457323, 0.088207  , 0.09379576, ..., 0.03754191, 0.06763539,\n",
       "        0.3292972 ],\n",
       "       [0.04712078, 0.17312135, 0.08276292, ..., 0.01070799, 0.10871429,\n",
       "        0.13007382],\n",
       "       [0.11083919, 0.08990058, 0.05844288, ..., 0.11467887, 0.01792909,\n",
       "        0.40573079],\n",
       "       ...,\n",
       "       [0.13123438, 0.04241704, 0.03760423, ..., 0.04842362, 0.16071272,\n",
       "        0.23585718],\n",
       "       [0.0363834 , 0.17145077, 0.1254504 , ..., 0.04064134, 0.1141165 ,\n",
       "        0.14325198],\n",
       "       [0.15675023, 0.12156284, 0.03439759, ..., 0.020586  , 0.06641229,\n",
       "        0.21616103]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y=tf.nn.softmax(X_train@W+b)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.559592805438929\n",
      "1 2.557433512319234\n",
      "2 2.5552858026979113\n",
      "3 2.553149542409012\n",
      "4 2.551024599343243\n",
      "5 2.548910843409527\n",
      "6 2.5468081464973946\n",
      "7 2.544716382440174\n",
      "8 2.542635426978972\n",
      "9 2.5405651577274257\n",
      "10 2.538505454137199\n",
      "11 2.5364561974642186\n",
      "12 2.534417270735628\n",
      "13 2.532388558717432\n",
      "14 2.5303699478828414\n",
      "15 2.5283613263812783\n",
      "16 2.526362584008028\n",
      "17 2.5243736121745446\n",
      "18 2.522394303879371\n",
      "19 2.5204245536796677\n",
      "20 2.5184642576633443\n",
      "21 2.516513313421767\n",
      "22 2.5145716200230344\n",
      "23 2.5126390779858134\n",
      "24 2.5107155892537167\n",
      "25 2.508801057170209\n",
      "26 2.5068953864540275\n",
      "27 2.5049984831751226\n",
      "28 2.503110254731079\n",
      "29 2.5012306098240265\n",
      "30 2.4993594584380245\n",
      "31 2.4974967118169045\n",
      "32 2.495642282442571\n",
      "33 2.493796084013734\n",
      "34 2.4919580314250798\n",
      "35 2.4901280407468604\n",
      "36 2.4883060292048937\n",
      "37 2.4864919151609692\n",
      "38 2.4846856180936436\n",
      "39 2.4828870585794243\n",
      "40 2.481096158274323\n",
      "41 2.479312839895785\n",
      "42 2.47753702720497\n",
      "43 2.4757686449893876\n",
      "44 2.4740076190458766\n",
      "45 2.4722538761639146\n",
      "46 2.470507344109265\n",
      "47 2.468767951607934\n",
      "48 2.4670356283304486\n",
      "49 2.4653103048764393\n",
      "50 2.46359191275952\n",
      "51 2.4618803843924644\n",
      "52 2.4601756530726693\n",
      "53 2.4584776529678924\n",
      "54 2.4567863191022727\n",
      "55 2.455101587342613\n",
      "56 2.4534233943849264\n",
      "57 2.45175167774124\n",
      "58 2.4500863757266487\n",
      "59 2.4484274274466147\n",
      "60 2.446774772784508\n",
      "61 2.445128352389379\n",
      "62 2.443488107663964\n",
      "63 2.441853980752915\n",
      "64 2.4402259145312475\n",
      "65 2.438603852593007\n",
      "66 2.4369877392401396\n",
      "67 2.4353775194715808\n",
      "68 2.433773138972528\n",
      "69 2.4321745441039324\n",
      "70 2.4305816818921637\n",
      "71 2.4289945000188764\n",
      "72 2.427412946811057\n",
      "73 2.4258369712312535\n",
      "74 2.4242665228679816\n",
      "75 2.4227015519263024\n",
      "76 2.4211420092185776\n",
      "77 2.4195878461553804\n",
      "78 2.418039014736578\n",
      "79 2.4164954675425716\n",
      "80 2.414957157725688\n",
      "81 2.4134240390017316\n",
      "82 2.4118960656416797\n",
      "83 2.4103731924635308\n",
      "84 2.4088553748242907\n",
      "85 2.407342568612103\n",
      "86 2.4058347302385164\n",
      "87 2.4043318166308874\n",
      "88 2.4028337852249155\n",
      "89 2.401340593957308\n",
      "90 2.399852201258571\n",
      "91 2.3983685660459266\n",
      "92 2.3968896477163506\n",
      "93 2.39541540613973\n",
      "94 2.393945801652138\n",
      "95 2.3924807950492237\n",
      "96 2.391020347579714\n",
      "97 2.389564420939029\n",
      "98 2.3881129772629954\n",
      "99 2.3866659791216804\n",
      "100 2.385223389513319\n",
      "101 2.383785171858345\n",
      "102 2.3823512899935246\n",
      "103 2.380921708166185\n",
      "104 2.3794963910285425\n",
      "105 2.3780753036321194\n",
      "106 2.376658411422257\n",
      "107 2.375245680232719\n",
      "108 2.3738370762803824\n",
      "109 2.372432566160015\n",
      "110 2.3710321168391415\n",
      "111 2.3696356956529865\n",
      "112 2.368243270299508\n",
      "113 2.3668548088345056\n",
      "114 2.36547027966681\n",
      "115 2.3640896515535497\n",
      "116 2.3627128935954937\n",
      "117 2.3613399752324664\n",
      "118 2.359970866238843\n",
      "119 2.358605536719106\n",
      "120 2.3572439571034836\n",
      "121 2.3558860981436474\n",
      "122 2.354531930908484\n",
      "123 2.3531814267799316\n",
      "124 2.351834557448882\n",
      "125 2.3504912949111487\n",
      "126 2.3491516114634905\n",
      "127 2.3478154796997086\n",
      "128 2.346482872506796\n",
      "129 2.3451537630611488\n",
      "130 2.343828124824836\n",
      "131 2.342505931541928\n",
      "132 2.341187157234881\n",
      "133 2.3398717762009738\n",
      "134 2.3385597630088037\n",
      "135 2.337251092494835\n",
      "136 2.3359457397599965\n",
      "137 2.3346436801663324\n",
      "138 2.3333448893337057\n",
      "139 2.3320493431365508\n",
      "140 2.3307570177006713\n",
      "141 2.3294678894000933\n",
      "142 2.328181934853954\n",
      "143 2.3268991309234512\n",
      "144 2.3256194547088263\n",
      "145 2.3243428835463966\n",
      "146 2.3230693950056343\n",
      "147 2.3217989668862846\n",
      "148 2.320531577215526\n",
      "149 2.3192672042451763\n",
      "150 2.3180058264489363\n",
      "151 2.3167474225196725\n",
      "152 2.3154919713667446\n",
      "153 2.314239452113368\n",
      "154 2.312989844094012\n",
      "155 2.311743126851845\n",
      "156 2.3104992801362045\n",
      "157 2.309258283900113\n",
      "158 2.3080201182978253\n",
      "159 2.30678476368241\n",
      "160 2.3055522006033713\n",
      "161 2.3043224098042945\n",
      "162 2.303095372220538\n",
      "163 2.3018710689769444\n",
      "164 2.300649481385595\n",
      "165 2.2994305909435915\n",
      "166 2.298214379330865\n",
      "167 2.297000828408025\n",
      "168 2.295789920214229\n",
      "169 2.294581636965088\n",
      "170 2.2933759610506006\n",
      "171 2.292172875033111\n",
      "172 2.290972361645302\n",
      "173 2.2897744037882117\n",
      "174 2.288578984529275\n",
      "175 2.287386087100402\n",
      "176 2.286195694896071\n",
      "177 2.2850077914714535\n",
      "178 2.2838223605405665\n",
      "179 2.282639385974446\n",
      "180 2.2814588517993464\n",
      "181 2.2802807421949676\n",
      "182 2.2791050414926994\n",
      "183 2.277931734173895\n",
      "184 2.27676080486817\n",
      "185 2.2755922383517144\n",
      "186 2.2744260195456394\n",
      "187 2.2732621335143337\n",
      "188 2.2721005654638557\n",
      "189 2.2709413007403345\n",
      "190 2.269784324828399\n",
      "191 2.268629623349626\n",
      "192 2.26747718206101\n",
      "193 2.266326986853451\n",
      "194 2.2651790237502616\n",
      "195 2.264033278905701\n",
      "196 2.2628897386035174\n",
      "197 2.261748389255516\n",
      "198 2.260609217400146\n",
      "199 2.259472209701102\n",
      "200 2.2583373529459485\n",
      "201 2.2572046340447574\n",
      "202 2.256074040028765\n",
      "203 2.2549455580490507\n",
      "204 2.2538191753752224\n",
      "205 2.2526948793941304\n",
      "206 2.251572657608589\n",
      "207 2.250452497636118\n",
      "208 2.2493343872077047\n",
      "209 2.2482183141665675\n",
      "210 2.247104266466955\n",
      "211 2.245992232172943\n",
      "212 2.2448821994572565\n",
      "213 2.243774156600102\n",
      "214 2.242668091988018\n",
      "215 2.2415639941127385\n",
      "216 2.240461851570066\n",
      "217 2.239361653058769\n",
      "218 2.238263387379483\n",
      "219 2.2371670434336286\n",
      "220 2.23607261022235\n",
      "221 2.2349800768454515\n",
      "222 2.233889432500364\n",
      "223 2.232800666481111\n",
      "224 2.2317137681772943\n",
      "225 2.230628727073092\n",
      "226 2.229545532746265\n",
      "227 2.2284641748671796\n",
      "228 2.227384643197839\n",
      "229 2.2263069275909277\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-91b496ebcdb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# categorical cross-entropy:-log(p)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my_oneshot\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mW_grads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_grads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1682\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_MatMulGradAgainstFirstOnly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1684\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_MatMulGradAgainstSecondOnly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1685\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[1;31m# No gradient skipping, so do the full gradient computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGradAgainstSecondOnly\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1663\u001b[0m   \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1665\u001b[1;33m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1666\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5524\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5525\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5526\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   5527\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5528\u001b[0m         transpose_b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_oneshot=np.eye(10)[y_train]\n",
    "eps=np.finfo(float).eps\n",
    "lr=0.001\n",
    "losses=[]\n",
    "for epoch in range(1000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_y=tf.nn.softmax(X_train@W+b)\n",
    "        # categorical cross-entropy:-log(p)\n",
    "        loss=tf.reduce_sum(-y_oneshot*tf.math.log(pred_y+eps))/len(y_train)\n",
    "    W_grads,b_grads=tape.gradient(loss,[W,b])\n",
    "    \n",
    "    W.assign_sub(lr*W_grads)\n",
    "    b.assign_sub(lr*b_grads)\n",
    "    losses.append(loss.numpy())\n",
    "    print(epoch,loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19fbf2c5100>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00431578492132879\n",
      "1 0.004313306867747228\n",
      "2 0.004310836622344495\n",
      "3 0.004308374125845143\n",
      "4 0.004305919319595509\n",
      "5 0.004303472145555462\n",
      "6 0.004301032546290253\n",
      "7 0.004298600464962519\n",
      "8 0.004296175845324401\n",
      "9 0.004293758631709798\n",
      "10 0.004291348769026744\n",
      "11 0.004288946202749896\n",
      "12 0.004286550878913159\n",
      "13 0.004284162744102414\n",
      "14 0.00428178174544837\n",
      "15 0.0042794078306195235\n",
      "16 0.004277040947815234\n",
      "17 0.0042746810457589\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-f536fa41b145>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my_oneshot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mW_grads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_grads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m_SoftmaxGrad\u001b[1;34m(op, grad_softmax)\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[0msoftmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m   \u001b[0msum_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_softmax\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgrad_softmax\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msum_channels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    516\u001b[0m   \"\"\"\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6061\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6062\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6063\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   6064\u001b[0m         _ctx, \"Mul\", name, x, y)\n\u001b[0;32m   6065\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 가중치 초기화\n",
    "W=tf.Variable(np.random.normal(0,0.1,size=[784,10]))\n",
    "b=tf.Variable(np.zeros(10))\n",
    "\n",
    "y_oneshot=np.eye(10)[y_train]\n",
    "eps=np.finfo(float).eps\n",
    "lr=0.001\n",
    "losses=[]\n",
    "\n",
    "for epoch in range(100):\n",
    "    for batch in range(600): #batch_size=100\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_y=tf.nn.softmax(X_train[batch*100:(batch+1)*100]@W+b)\n",
    "            # categorical cross-entropy:-log(p)\n",
    "            \n",
    "            loss=tf.reduce_sum(-y_oneshot[batch*100:(batch+1)*100]*tf.math.log(pred_y+eps))/len(y_train)\n",
    "        W_grads,b_grads=tape.gradient(loss,[W,b])\n",
    "    \n",
    "        W.assign_sub(lr*W_grads)\n",
    "        b.assign_sub(lr*b_grads)\n",
    "    losses.append(loss.numpy())\n",
    "    print(epoch,loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.optimizers.RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(10,input_shape=(784,),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 692us/step - loss: 1.5816\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 662us/step - loss: 0.6970\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.5586\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 1s 865us/step - loss: 0.4980\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 1s 899us/step - loss: 0.4668\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 1s 896us/step - loss: 0.4369\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 774us/step - loss: 0.4207\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 713us/step - loss: 0.4042\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 668us/step - loss: 0.3959\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 756us/step - loss: 0.3883\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 1s 896us/step - loss: 0.3808\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 1s 892us/step - loss: 0.3747\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 1s 887us/step - loss: 0.3646\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 1s 908us/step - loss: 0.3652\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 1s 912us/step - loss: 0.3555\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 740us/step - loss: 0.3596\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 731us/step - loss: 0.3491\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 703us/step - loss: 0.3459\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 691us/step - loss: 0.3466\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 677us/step - loss: 0.3454\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 747us/step - loss: 0.3431\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 693us/step - loss: 0.3387\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 651us/step - loss: 0.3299\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 683us/step - loss: 0.3314\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 701us/step - loss: 0.3358\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 685us/step - loss: 0.3275\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 722us/step - loss: 0.3258\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 672us/step - loss: 0.3248\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 670us/step - loss: 0.3199\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 671us/step - loss: 0.3186\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 669us/step - loss: 0.3174\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 666us/step - loss: 0.3168\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 678us/step - loss: 0.3139\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 680us/step - loss: 0.3203\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 677us/step - loss: 0.3124\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 674us/step - loss: 0.3171\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 661us/step - loss: 0.3112\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 661us/step - loss: 0.3116\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 675us/step - loss: 0.3055\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 674us/step - loss: 0.3064\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 670us/step - loss: 0.3117\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 671us/step - loss: 0.3041\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 668us/step - loss: 0.3058\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 671us/step - loss: 0.3080\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 679us/step - loss: 0.3052\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 687us/step - loss: 0.3053\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 688us/step - loss: 0.3042\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 711us/step - loss: 0.3040\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 715us/step - loss: 0.2966\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 715us/step - loss: 0.2974\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 729us/step - loss: 0.3020\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 740us/step - loss: 0.3041\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 722us/step - loss: 0.2966\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 741us/step - loss: 0.2968\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 730us/step - loss: 0.2951\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 738us/step - loss: 0.3055\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 742us/step - loss: 0.2942\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 734us/step - loss: 0.2973\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 756us/step - loss: 0.2972\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 733us/step - loss: 0.2980\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 740us/step - loss: 0.2875\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 745us/step - loss: 0.2897\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 750us/step - loss: 0.2977\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 751us/step - loss: 0.2911\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 736us/step - loss: 0.2944\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 774us/step - loss: 0.2915\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 770us/step - loss: 0.2893\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 759us/step - loss: 0.2915\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 753us/step - loss: 0.2897\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 745us/step - loss: 0.2895\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 755us/step - loss: 0.2936\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 754us/step - loss: 0.2908\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 763us/step - loss: 0.2910\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 766us/step - loss: 0.2933\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 769us/step - loss: 0.2922\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 767us/step - loss: 0.2884\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 775us/step - loss: 0.2871\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 767us/step - loss: 0.2845\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 788us/step - loss: 0.2879\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 775us/step - loss: 0.2813\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 768us/step - loss: 0.2901\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 763us/step - loss: 0.2875\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 779us/step - loss: 0.2853\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 788us/step - loss: 0.2836\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 779us/step - loss: 0.2772\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 771us/step - loss: 0.2808\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 783us/step - loss: 0.2855\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 784us/step - loss: 0.2823\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 788us/step - loss: 0.2808\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 777us/step - loss: 0.2825\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 779us/step - loss: 0.2868\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 772us/step - loss: 0.2829\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 783us/step - loss: 0.2866\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 783us/step - loss: 0.2792\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 781us/step - loss: 0.2809\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 782us/step - loss: 0.2791\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 738us/step - loss: 0.2821\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 738us/step - loss: 0.2821\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 745us/step - loss: 0.2839\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 728us/step - loss: 0.2738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19fc00ba160>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='sgd')\n",
    "y_oneshot=np.eye(10)[y_train]\n",
    "model.fit(X_train,y_oneshot,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19fc01691f0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h=model.history.history\n",
    "plt.plot(h['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
